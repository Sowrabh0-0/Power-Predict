{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-10-22T19:17:13.340107400Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "from torchvision.models import EfficientNet_B0_Weights\n",
    "import torch.autograd.profiler as profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T19:17:13.392819900Z",
     "start_time": "2024-10-22T19:17:13.378271900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Path to the Excel file with refractive error data\n",
    "excel_file_path = './ODOCS RED REFLEX DATABASE/Choithram Netralaya Data/acuityvalues.xlsx'\n",
    "\n",
    "# Load the Excel file containing refractive error data\n",
    "acuity_data = pd.read_excel(excel_file_path)\n",
    "\n",
    "# Display the first few rows to check the loaded data\n",
    "print(acuity_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Path to your dataset directory (relative to the notebook's location)\n",
    "dataset_path = './ODOCS RED REFLEX DATABASE/Choithram Netralaya Data/Images'\n",
    "\n",
    "# Supported image formats\n",
    "image_extensions = ['.jpg', '.jpeg', '.png']\n",
    "\n",
    "# Function to load and organize images, checking for both raw and cropped versions\n",
    "def load_images_from_directory(directory_path):\n",
    "    images = []\n",
    "    image_metadata = []\n",
    "    \n",
    "    for root, _, files in os.walk(directory_path):\n",
    "        if not files:\n",
    "            print(f\"Skipping empty folder: {root}\")\n",
    "            continue  # Skip empty folders\n",
    "        \n",
    "        for file in files:\n",
    "            # Check if file is an image\n",
    "            if any(file.lower().endswith(ext) for ext in image_extensions):\n",
    "                file_path = os.path.join(root, file)\n",
    "                \n",
    "                # Check if the image is a raw or cropped version\n",
    "                is_cropped = file.endswith('s.jpg')\n",
    "                \n",
    "                # Extract relevant metadata (eye type, date, cropped/raw) from the filename\n",
    "                eye_type = \"OD\" if \"OD\" in file else \"OS\"  # Right Eye or Left Eye\n",
    "                date_info = file.split('-')[0]  # Extract date from filename (e.g., 2022-12-08)\n",
    "                \n",
    "                try:\n",
    "                    # Load the image using Pillow (PIL)\n",
    "                    image = Image.open(file_path)\n",
    "                    \n",
    "                    # Append the image and its metadata to the list\n",
    "                    images.append(image)\n",
    "                    image_metadata.append({\n",
    "                        'filename': file,\n",
    "                        'eye_type': eye_type,\n",
    "                        'date_info': date_info,\n",
    "                        'is_cropped': is_cropped,\n",
    "                        'path': file_path\n",
    "                    })\n",
    "                    \n",
    "                    print(f\"Loaded {file} from {root}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading image {file}: {e}\")\n",
    "    \n",
    "    return images, image_metadata\n",
    "\n",
    "# Load all images from the dataset\n",
    "images, metadata = load_images_from_directory(dataset_path)\n",
    "\n",
    "# Check the number of images loaded\n",
    "print(f\"Total images loaded: {len(images)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-22T19:17:13.396354300Z",
     "start_time": "2024-10-22T19:17:13.396354300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to map images to acuity data using the folder name for patient ID\n",
    "def map_images_to_acuity(images_metadata, acuity_data):\n",
    "    mapped_data = []\n",
    "    \n",
    "    for meta in images_metadata:\n",
    "        # Extract patient ID from the folder structure (assuming the folder name is the patient number)\n",
    "        # Use the os.path.split() to get the folder name from the file path\n",
    "        folder_name = os.path.basename(os.path.dirname(meta['path']))\n",
    "        \n",
    "        try:\n",
    "            patient_id = int(folder_name)  # Convert folder name to integer for matching\n",
    "        except ValueError:\n",
    "            # If folder name is not an integer, skip this entry\n",
    "            print(f\"Skipping {meta['filename']} as folder name '{folder_name}' is not a valid patient ID.\")\n",
    "            continue\n",
    "        \n",
    "        eye = meta['eye_type']\n",
    "        \n",
    "        # Find corresponding acuity data for the patient\n",
    "        patient_data = acuity_data[acuity_data['patient'] == patient_id]\n",
    "        if not patient_data.empty:\n",
    "            if eye == 'OD':\n",
    "                meta['sphere'] = patient_data['r sphere'].values[0]\n",
    "                meta['cylinder'] = patient_data['r cylinder'].values[0]\n",
    "            else:\n",
    "                meta['sphere'] = patient_data['l sphere'].values[0]\n",
    "                meta['cylinder'] = patient_data['l cylinder'].values[0]\n",
    "            \n",
    "            mapped_data.append(meta)\n",
    "    \n",
    "    return mapped_data\n",
    "\n",
    "# Map images to acuity data\n",
    "mapped_images = map_images_to_acuity(metadata, acuity_data)\n",
    "\n",
    "# Display the mapped data\n",
    "print(mapped_images[:5])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-22T19:17:13.411898100Z",
     "start_time": "2024-10-22T19:17:13.397357600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check if CUDA is available and set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Preprocessing transformations (e.g., for EfficientNet)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),  # Resize to 299x299 (EfficientNet input size)\n",
    "    transforms.ToTensor(),          # Convert to PyTorch Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize as required\n",
    "])\n",
    "\n",
    "# Custom dataset class to handle our images and labels\n",
    "class RedReflexDataset(Dataset):\n",
    "    def __init__(self, images_metadata, transform=None):\n",
    "        self.images_metadata = images_metadata\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images_metadata[idx]['path']\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')  # Convert to RGB\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            return None, None, None\n",
    "        \n",
    "        # Apply transformations if they exist\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Get sphere and cylinder labels\n",
    "        sphere = torch.tensor([self.images_metadata[idx]['sphere']], dtype=torch.float32)\n",
    "        cylinder = torch.tensor([self.images_metadata[idx]['cylinder']], dtype=torch.float32)\n",
    "\n",
    "        return image, sphere, cylinder\n",
    "\n",
    "# Load the dataset\n",
    "dataset = RedReflexDataset(mapped_images, transform=transform)\n",
    "\n",
    "# Create DataLoader with multiple workers to load data in parallel\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=0, pin_memory=True)\n",
    "\n",
    "# Load EfficientNet model with updated weights parameter\n",
    "from torchvision.models import EfficientNet_B0_Weights\n",
    "model = models.efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "model.classifier[1] = nn.Linear(in_features=model.classifier[1].in_features, out_features=2)  # Adjust for sphere and cylinder output\n",
    "\n",
    "# Move model to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# Print model architecture\n",
    "print(model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-10-22T19:17:13.404360800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Mixed precision training setup\n",
    "scaler = torch.amp.GradScaler('cuda')\n",
    "\n",
    "# Loss function (Mean Squared Error, suitable for regression tasks like ours)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Optimizer (we use Adam for optimization)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-22T19:17:13.305913700Z",
     "start_time": "2024-10-22T19:17:13.305011800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Training loop\n",
    "epochs = 5  # Number of training epochs\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for images, spheres, cylinders in dataloader:\n",
    "        images, spheres, cylinders = images.to(device), spheres.to(device), cylinders.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass with mixed precision\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(images)\n",
    "            predicted_spheres, predicted_cylinders = outputs[:, 0], outputs[:, 1]\n",
    "            \n",
    "            # Calculate losses\n",
    "            loss_sphere = criterion(predicted_spheres, spheres)\n",
    "            loss_cylinder = criterion(predicted_cylinders, cylinders)\n",
    "            loss = loss_sphere + loss_cylinder\n",
    "        \n",
    "        # Backward pass and optimization with scaled gradients\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        # Track loss\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(dataloader):.4f}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-22T19:17:13.340107400Z",
     "start_time": "2024-10-22T19:17:13.339104200Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
