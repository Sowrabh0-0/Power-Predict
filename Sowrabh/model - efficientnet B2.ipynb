#%%
import torch
import torchvision
import torchvision.transforms as T
import pandas as pd
from PIL import Image
import os
import logging
from torch.utils.data import Dataset
import torch.nn as nn

print("PyTorch version:", torch.__version__)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device:", device)
#%%
acuity_path = "../Choithram Netralaya Data/acuityvalues.xlsx"

df = pd.read_excel(acuity_path)

display(df.head())

print("Columns in the dataset:")
print(df.columns)
#%%
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')

filtered_df = df.copy()
numeric_cols = ['r sphere', 'r cylinder', 'l sphere', 'l cylinder']

filtered_df = filtered_df.dropna(subset=numeric_cols)

df_patients = set(map(str, filtered_df['patient'].unique()))

data_dir = "../Choithram Netralaya Data/Images"
image_patients = set()
if os.path.exists(data_dir):
    for folder_name in os.listdir(data_dir):
        folder_path = os.path.join(data_dir, folder_name)
        if os.path.isdir(folder_path):
            image_patients.add(folder_name)
else:
    logging.warning("Image directory does not exist!")

all_patients = df_patients.union(image_patients)

valid_patients = []
logging.info(f"Total patients in DF (after NaN drop): {len(df_patients)}")
logging.info(f"Total patients in image directory: {len(image_patients)}")
logging.info(f"Combined unique patients: {len(all_patients)}")

for patient_id in sorted(all_patients, key=lambda x: int(x)):
    if patient_id not in df_patients:
        logging.info(f"Skipping patient {patient_id}: no numeric values found in DataFrame.")
        continue
    row = filtered_df.loc[filtered_df['patient'] == int(patient_id)].head(1)
    if row.empty:
        logging.info(f"Skipping patient {patient_id}: filtered out due to missing numeric data.")
        continue

    left_ir_path = os.path.join(data_dir, patient_id, f"{patient_id}_LEFT_IR.jpg")
    right_ir_path = os.path.join(data_dir, patient_id, f"{patient_id}_RIGHT_IR.jpg")

    left_exists = os.path.exists(left_ir_path)
    right_exists = os.path.exists(right_ir_path)

    if not left_exists and not right_exists:
        logging.info(f"Skipping patient {patient_id}: LEFT_IR and RIGHT_IR images missing.")
        continue
    elif not left_exists:
        logging.info(f"Skipping patient {patient_id}: LEFT_IR image missing.")
        continue
    elif not right_exists:
        logging.info(f"Skipping patient {patient_id}: RIGHT_IR image missing.")
        continue

    logging.info(f"Including patient {patient_id}: Numeric and IR images available.")
    valid_patients.append(patient_id)

valid_patient_ids = set(map(int, valid_patients))
filtered_df = filtered_df[filtered_df['patient'].isin(valid_patient_ids)].reset_index(drop=True)

logging.info(f"Number of valid patients after filtering: {len(filtered_df)}")
#%%
class EyeIRDataset(Dataset):
    def __init__(self, df, data_dir, transform=None, is_training=True):
        """
        Args:
            df (DataFrame): Data containing patient IDs and numerical features.
            data_dir (str): Directory where images are stored.
            transform: Image transformations.
            is_training (bool): Whether the dataset is for training or testing.
        """
        self.df = df
        self.data_dir = data_dir
        self.transform = transform
        self.is_training = is_training

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]

        # Use patient_id internally for loading images
        patient_id = str(int(row['patient']))
        left_ir_path = os.path.join(self.data_dir, patient_id, f"{patient_id}_LEFT_IR.jpg")
        right_ir_path = os.path.join(self.data_dir, patient_id, f"{patient_id}_RIGHT_IR.jpg")

        left_img = Image.open(left_ir_path).convert("RGB")
        right_img = Image.open(right_ir_path).convert("RGB")

        if self.transform:
            left_img = self.transform(left_img)
            right_img = self.transform(right_img)

        # For training, include numeric features and targets
        if self.is_training:
            numeric_features = torch.tensor(
                [row['r sphere'], row['r cylinder'], row['l sphere'], row['l cylinder']],
                dtype=torch.float
            )
            target = numeric_features.clone()  # Targets are the same as numeric features
            return {
                "left_ir": left_img,
                "right_ir": right_img,
                "numeric_features": numeric_features,
                "target": target
            }
        else:  # For testing, only return images
            return {
                "left_ir": left_img,
                "right_ir": right_img
            }
#%%
transform = T.Compose([
    T.Resize((224, 224)),
    T.ToTensor()
])

data_dir = "../Choithram Netralaya Data/Images"
dataset = EyeIRDataset(filtered_df, data_dir, transform=transform)
#%%
from sklearn.model_selection import train_test_split

# Split the dataset into training and testing sets
train_df, test_df = train_test_split(filtered_df, test_size=0.2, random_state=42)

#%%
# import torchvision.transforms as T
#
# # Augmentation pipeline for training
# train_transform = T.Compose([
#     T.Resize((240, 240)),  # Resize to match EfficientNet B2 input size
#     T.RandomRotation(15),  # Random rotations for robustness
#     T.RandomHorizontalFlip(p=0.5),  # Random horizontal flip
#     T.ColorJitter(brightness=0.2, contrast=0.2),  # Brightness/contrast augmentation
#     T.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Random translations
#     T.ToTensor(),  # Convert to tensor
# ])
#
# # Minimal transformations for validation
# val_transform = T.Compose([
#     T.Resize((240, 240)),  # Resize to match model input size
#     T.ToTensor(),  # Convert to tensor
# ])




# Augmentation for training
train_transform = T.Compose([
    T.Resize((240, 240)),
    T.RandomRotation(15),
    T.RandomHorizontalFlip(p=0.5),
    T.ColorJitter(brightness=0.2, contrast=0.2),
    T.RandomAffine(degrees=0, translate=(0.1, 0.1)),
    T.GaussianBlur(kernel_size=(3, 3)),  # Add Gaussian blur for robustness
    T.ToTensor(),
])

# Validation (no augmentations)
val_transform = T.Compose([
    T.Resize((240, 240)),
    T.ToTensor(),
])

#%%
# Create training and validation datasets
train_dataset = EyeIRDataset(train_df, data_dir, transform=train_transform, is_training=True)
val_dataset = EyeIRDataset(test_df, data_dir, transform=val_transform, is_training=True)

#%%
from torch.utils.data import DataLoader

# Create data loaders for training and validation
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)

#%%
class EyeModelB2(nn.Module):
    def __init__(self, output_dim=4):
        super(EyeModelB2, self).__init__()
        # Load EfficientNet B2 for image processing
        self.cnn = efficientnet_b2(weights=EfficientNet_B2_Weights.IMAGENET1K_V1)
        self.cnn.classifier = nn.Identity()  # Remove default classifier

        # Define a fully connected layer to compress image features
        self.img_compress = nn.Linear(1408 * 2, 512)  # 1408 output features from EfficientNet B2

        # Define a small MLP for numeric features
        self.numeric_branch = nn.Sequential(
            nn.Linear(4, 64),  # 4 numeric features
            nn.ReLU(),
            nn.Linear(64, 32)
        )

        # Combine all features and output the final prediction
        self.fc = nn.Sequential(
            nn.Linear(512 + 32, 128),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(128, output_dim)
        )

    def forward(self, left_ir, right_ir, numeric):
        # Extract features from both images
        left_feat = self.cnn(left_ir)  # Shape: [batch_size, 1408]
        right_feat = self.cnn(right_ir)  # Shape: [batch_size, 1408]

        # Concatenate image features and compress
        combined_img_feat = torch.cat([left_feat, right_feat], dim=1)
        combined_img_feat = self.img_compress(combined_img_feat)

        # Process numeric features
        numeric_feat = self.numeric_branch(numeric)

        # Fuse image and numeric features
        fused_feat = torch.cat([combined_img_feat, numeric_feat], dim=1)

        # Final prediction
        out = self.fc(fused_feat)
        return out

#%%
from torch import nn
from torch.optim import AdamW
from torchvision.models import efficientnet_b2, EfficientNet_B2_Weights

# Define the model
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = EyeModelB2(output_dim=4).to(device)

# Define the loss function and optimizer
criterion = nn.MSELoss()  # Mean Squared Error Loss
optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)

# Define the learning rate scheduler
from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts
scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)

#%%
import  numpy as np

# Metric calculation function (feature-specific)
# Metric calculation function (overall)
def calculate_metrics(predictions, targets):
    """
    Calculates overall metrics: Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and R-squared (R²).
    Args:
        predictions (Tensor): Predicted values from the model.
        targets (Tensor): Ground truth values.
    Returns:
        tuple: MAE, RMSE, R² for the entire batch.
    """
    predictions = predictions.detach().cpu().numpy()
    targets = targets.detach().cpu().numpy()

    # Calculate Mean Absolute Error
    mae = np.mean(np.abs(predictions - targets))

    # Calculate Root Mean Squared Error
    rmse = np.sqrt(np.mean((predictions - targets) ** 2))

    # Calculate R² (Coefficient of Determination)
    total_variance = np.sum((targets - np.mean(targets)) ** 2)
    explained_variance = np.sum((predictions - targets) ** 2)
    r_squared = 1 - (explained_variance / total_variance) if total_variance != 0 else 0

    return mae, rmse, r_squared

def calculate_feature_metrics(predictions, targets):
    predictions = predictions.detach().cpu().numpy()
    targets = targets.detach().cpu().numpy()
    feature_metrics = {}

    for i, feature in enumerate(['r sphere', 'r cylinder', 'l sphere', 'l cylinder']):
        pred = predictions[:, i]
        tgt = targets[:, i]
        mae = np.mean(np.abs(pred - tgt))
        rmse = np.sqrt(np.mean((pred - tgt) ** 2))
        r_squared = 1 - (np.sum((tgt - pred) ** 2) / np.sum((tgt - np.mean(tgt)) ** 2))
        feature_metrics[feature] = {'mae': mae, 'rmse': rmse, 'r2': r_squared}

    return feature_metrics

class EarlyStopping:
    def __init__(self, patience=5, delta=0.01, verbose=True):
        self.patience = patience
        self.delta = delta
        self.best_loss = None
        self.counter = 0
        self.early_stop = False
        self.verbose = verbose

    def __call__(self, val_loss):
        if self.best_loss is None:
            self.best_loss = val_loss
        elif val_loss > self.best_loss - self.delta:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True
                if self.verbose:
                    print("Early stopping triggered!")
        else:
            self.best_loss = val_loss
            self.counter = 0

# Training loop
epochs = 30
early_stopping = EarlyStopping(patience=5, delta=0.01)
best_val_loss = float("inf")

for epoch in range(epochs):
    # Training phase
    model.train()
    train_loss, train_mae, train_rmse, train_r2 = 0, 0, 0, 0
    train_feature_metrics = {'r sphere': {'mae': 0, 'rmse': 0, 'r2': 0},
                             'r cylinder': {'mae': 0, 'rmse': 0, 'r2': 0},
                             'l sphere': {'mae': 0, 'rmse': 0, 'r2': 0},
                             'l cylinder': {'mae': 0, 'rmse': 0, 'r2': 0}}

    for batch in train_loader:
        left_ir = batch['left_ir'].to(device)
        right_ir = batch['right_ir'].to(device)
        numeric = batch['numeric_features'].to(device)
        target = batch['target'].to(device)

        optimizer.zero_grad()
        predictions = model(left_ir, right_ir, numeric)
        loss = criterion(predictions, target)
        loss.backward()
        optimizer.step()

        train_loss += loss.item()
        mae, rmse, r2 = calculate_metrics(predictions, target)
        train_mae += mae
        train_rmse += rmse
        train_r2 += r2

        # Feature-specific metrics
        batch_feature_metrics = calculate_feature_metrics(predictions, target)
        for feature in train_feature_metrics:
            train_feature_metrics[feature]['mae'] += batch_feature_metrics[feature]['mae']
            train_feature_metrics[feature]['rmse'] += batch_feature_metrics[feature]['rmse']
            train_feature_metrics[feature]['r2'] += batch_feature_metrics[feature]['r2']

    train_loss /= len(train_loader)
    train_mae /= len(train_loader)
    train_rmse /= len(train_loader)
    train_r2 /= len(train_loader)
    for feature in train_feature_metrics:
        train_feature_metrics[feature]['mae'] /= len(train_loader)
        train_feature_metrics[feature]['rmse'] /= len(train_loader)
        train_feature_metrics[feature]['r2'] /= len(train_loader)

    # Validation phase
    model.eval()
    val_loss, val_mae, val_rmse, val_r2 = 0, 0, 0, 0
    val_feature_metrics = {'r sphere': {'mae': 0, 'rmse': 0, 'r2': 0},
                           'r cylinder': {'mae': 0, 'rmse': 0, 'r2': 0},
                           'l sphere': {'mae': 0, 'rmse': 0, 'r2': 0},
                           'l cylinder': {'mae': 0, 'rmse': 0, 'r2': 0}}

    with torch.no_grad():
        for batch in val_loader:
            left_ir = batch['left_ir'].to(device)
            right_ir = batch['right_ir'].to(device)
            numeric = batch['numeric_features'].to(device)
            target = batch['target'].to(device)

            predictions = model(left_ir, right_ir, numeric)
            loss = criterion(predictions, target)

            val_loss += loss.item()
            mae, rmse, r2 = calculate_metrics(predictions, target)
            val_mae += mae
            val_rmse += rmse
            val_r2 += r2

            # Feature-specific metrics
            batch_feature_metrics = calculate_feature_metrics(predictions, target)
            for feature in val_feature_metrics:
                val_feature_metrics[feature]['mae'] += batch_feature_metrics[feature]['mae']
                val_feature_metrics[feature]['rmse'] += batch_feature_metrics[feature]['rmse']
                val_feature_metrics[feature]['r2'] += batch_feature_metrics[feature]['r2']

    val_loss /= len(val_loader)
    val_mae /= len(val_loader)
    val_rmse /= len(val_loader)
    val_r2 /= len(val_loader)
    for feature in val_feature_metrics:
        val_feature_metrics[feature]['mae'] /= len(val_loader)
        val_feature_metrics[feature]['rmse'] /= len(val_loader)
        val_feature_metrics[feature]['r2'] /= len(val_loader)

    # Adjust learning rate
    scheduler.step()

    # Save best model
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        torch.save(model.state_dict(), f"best_model_epoch_{epoch+1}.pth")

    # Print metrics for this epoch
    print(
        f"Epoch [{epoch+1}/{epochs}], LR: {scheduler.get_last_lr()[0]:.6f}\n"
        f"Train Loss: {train_loss:.4f}, MAE: {train_mae:.4f}, RMSE: {train_rmse:.4f}, R²: {train_r2:.4f}\n"
        f"Val Loss: {val_loss:.4f}, MAE: {val_mae:.4f}, RMSE: {val_rmse:.4f}, R²: {val_r2:.4f}\n"
    )
    print("Feature-Specific Metrics (Train):")
    for feature, metrics in train_feature_metrics.items():
        print(f"  {feature}: MAE: {metrics['mae']:.4f}, RMSE: {metrics['rmse']:.4f}, R²: {metrics['r2']:.4f}")
    print("Feature-Specific Metrics (Validation):")
    for feature, metrics in val_feature_metrics.items():
        print(f"  {feature}: MAE: {metrics['mae']:.4f}, RMSE: {metrics['rmse']:.4f}, R²: {metrics['r2']:.4f}")

    # Early stopping
    early_stopping(val_loss)
    if early_stopping.early_stop:
        print("Early stopping triggered!")
        break
#%%
import numpy as np
from torch import nn

# Weighted MSE Loss Class
class WeightedMSELoss(nn.Module):
    def __init__(self, weights):
        super(WeightedMSELoss, self).__init__()
        self.weights = weights

    def forward(self, predictions, targets):
        # Weighted mean squared error
        loss = (self.weights * (predictions - targets) ** 2).mean()
        return loss

# Assign weights (higher weights for r cylinder and l cylinder)
weights = torch.tensor([1.0, 1.5, 1.0, 1.5], device=device)  # Adjust weights as needed
criterion = WeightedMSELoss(weights)

# Metric calculation function (overall)
def calculate_metrics(predictions, targets):
    predictions = predictions.detach().cpu().numpy()
    targets = targets.detach().cpu().numpy()
    mae = np.mean(np.abs(predictions - targets))
    rmse = np.sqrt(np.mean((predictions - targets) ** 2))
    total_variance = np.sum((targets - np.mean(targets)) ** 2)
    explained_variance = np.sum((predictions - targets) ** 2)
    r_squared = 1 - (explained_variance / total_variance) if total_variance != 0 else 0
    return mae, rmse, r_squared

# Metric calculation function (feature-specific)
def calculate_feature_metrics(predictions, targets):
    predictions = predictions.detach().cpu().numpy()
    targets = targets.detach().cpu().numpy()
    feature_metrics = {}

    for i, feature in enumerate(['r sphere', 'r cylinder', 'l sphere', 'l cylinder']):
        pred = predictions[:, i]
        tgt = targets[:, i]
        mae = np.mean(np.abs(pred - tgt))
        rmse = np.sqrt(np.mean((pred - tgt) ** 2))
        r_squared = 1 - (np.sum((tgt - pred) ** 2) / np.sum((tgt - np.mean(tgt)) ** 2))
        feature_metrics[feature] = {'mae': mae, 'rmse': rmse, 'r2': r_squared}

    return feature_metrics

# Early stopping class
class EarlyStopping:
    def __init__(self, patience=5, delta=0.01, verbose=True):
        self.patience = patience
        self.delta = delta
        self.best_loss = None
        self.counter = 0
        self.early_stop = False
        self.verbose = verbose

    def __call__(self, val_loss):
        if self.best_loss is None:
            self.best_loss = val_loss
        elif val_loss > self.best_loss - self.delta:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True
                if self.verbose:
                    print("Early stopping triggered!")
        else:
            self.best_loss = val_loss
            self.counter = 0

# Training loop
epochs = 30
early_stopping = EarlyStopping(patience=5, delta=0.01)
best_val_loss = float("inf")

for epoch in range(epochs):
    # Training phase
    model.train()
    train_loss, train_mae, train_rmse, train_r2 = 0, 0, 0, 0
    train_feature_metrics = {'r sphere': {'mae': 0, 'rmse': 0, 'r2': 0},
                             'r cylinder': {'mae': 0, 'rmse': 0, 'r2': 0},
                             'l sphere': {'mae': 0, 'rmse': 0, 'r2': 0},
                             'l cylinder': {'mae': 0, 'rmse': 0, 'r2': 0}}

    for batch in train_loader:
        left_ir = batch['left_ir'].to(device)
        right_ir = batch['right_ir'].to(device)
        numeric = batch['numeric_features'].to(device)
        target = batch['target'].to(device)

        optimizer.zero_grad()
        predictions = model(left_ir, right_ir, numeric)
        loss = criterion(predictions, target)
        loss.backward()
        optimizer.step()

        train_loss += loss.item()
        mae, rmse, r2 = calculate_metrics(predictions, target)
        train_mae += mae
        train_rmse += rmse
        train_r2 += r2

        # Feature-specific metrics
        batch_feature_metrics = calculate_feature_metrics(predictions, target)
        for feature in train_feature_metrics:
            train_feature_metrics[feature]['mae'] += batch_feature_metrics[feature]['mae']
            train_feature_metrics[feature]['rmse'] += batch_feature_metrics[feature]['rmse']
            train_feature_metrics[feature]['r2'] += batch_feature_metrics[feature]['r2']

    train_loss /= len(train_loader)
    train_mae /= len(train_loader)
    train_rmse /= len(train_loader)
    train_r2 /= len(train_loader)
    for feature in train_feature_metrics:
        train_feature_metrics[feature]['mae'] /= len(train_loader)
        train_feature_metrics[feature]['rmse'] /= len(train_loader)
        train_feature_metrics[feature]['r2'] /= len(train_loader)

    # Validation phase
    model.eval()
    val_loss, val_mae, val_rmse, val_r2 = 0, 0, 0, 0
    val_feature_metrics = {'r sphere': {'mae': 0, 'rmse': 0, 'r2': 0},
                           'r cylinder': {'mae': 0, 'rmse': 0, 'r2': 0},
                           'l sphere': {'mae': 0, 'rmse': 0, 'r2': 0},
                           'l cylinder': {'mae': 0, 'rmse': 0, 'r2': 0}}

    with torch.no_grad():
        for batch in val_loader:
            left_ir = batch['left_ir'].to(device)
            right_ir = batch['right_ir'].to(device)
            numeric = batch['numeric_features'].to(device)
            target = batch['target'].to(device)

            predictions = model(left_ir, right_ir, numeric)
            loss = criterion(predictions, target)

            val_loss += loss.item()
            mae, rmse, r2 = calculate_metrics(predictions, target)
            val_mae += mae
            val_rmse += rmse
            val_r2 += r2

            # Feature-specific metrics
            batch_feature_metrics = calculate_feature_metrics(predictions, target)
            for feature in val_feature_metrics:
                val_feature_metrics[feature]['mae'] += batch_feature_metrics[feature]['mae']
                val_feature_metrics[feature]['rmse'] += batch_feature_metrics[feature]['rmse']
                val_feature_metrics[feature]['r2'] += batch_feature_metrics[feature]['r2']

    val_loss /= len(val_loader)
    val_mae /= len(val_loader)
    val_rmse /= len(val_loader)
    val_r2 /= len(val_loader)
    for feature in val_feature_metrics:
        val_feature_metrics[feature]['mae'] /= len(val_loader)
        val_feature_metrics[feature]['rmse'] /= len(val_loader)
        val_feature_metrics[feature]['r2'] /= len(val_loader)

    # Adjust learning rate
    scheduler.step()

    # Save best model
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        # torch.save(model.state_dict(), f"best_model_epoch_{epoch+1}.pth")

    # Print metrics for this epoch
    print(
        f"Epoch [{epoch+1}/{epochs}], LR: {scheduler.get_last_lr()[0]:.6f}\n"
        f"Train Loss: {train_loss:.4f}, MAE: {train_mae:.4f}, RMSE: {train_rmse:.4f}, R²: {train_r2:.4f}\n"
        f"Val Loss: {val_loss:.4f}, MAE: {val_mae:.4f}, RMSE: {val_rmse:.4f}, R²: {val_r2:.4f}\n"
    )
    print("Feature-Specific Metrics (Train):")
    for feature, metrics in train_feature_metrics.items():
        print(f"  {feature}: MAE: {metrics['mae']:.4f}, RMSE: {metrics['rmse']:.4f}, R²: {metrics['r2']:.4f}")
    print("Feature-Specific Metrics (Validation):")
    for feature, metrics in val_feature_metrics.items():
        print(f"  {feature}: MAE: {metrics['mae']:.4f}, RMSE: {metrics['rmse']:.4f}, R²: {metrics['r2']:.4f}")

    # Early stopping
    early_stopping(val_loss)
    if early_stopping.early_stop:
        print("Early stopping triggered!")
        break
